{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the ImageNet dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 02:22:55.642900: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-08-19 02:22:55.642950: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-08-19 02:22:55.642966: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2025-08-19 02:22:55.642997: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-08-19 02:22:55.643013: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting samples per class...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 02:33:25.625086: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: ../datasets/imagenet2012/5.1.0/imagenet2012-train.tfrecord-00026-of-01024; Operation canceled\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ../datasets/imagenet2012/5.1.0/imagenet2012-train.tfrecord-00026-of-01024; Operation canceled [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Create a dictionary to hold the counts for each of the 1000 ImageNet labels.\u001b[39;00m\n\u001b[32m     24\u001b[39m class_counts = {label: \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m)}\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds_train_full\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# --- Step 2: Determine split sizes per class ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-stanlee.okwii@gmail.com/My Drive/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[39m, in \u001b[36mOwnedIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    808\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    810\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m errors.OutOfRangeError:\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-stanlee.okwii@gmail.com/My Drive/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[39m, in \u001b[36mOwnedIterator._next_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    769\u001b[39m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context.execution_mode(context.SYNC):\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m   ret = \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    774\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    777\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    778\u001b[39m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[32m    779\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._element_spec._from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-stanlee.okwii@gmail.com/My Drive/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[39m, in \u001b[36miterator_get_next\u001b[39m\u001b[34m(iterator, output_types, output_shapes, name)\u001b[39m\n\u001b[32m   3084\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3086\u001b[39m   \u001b[43m_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3087\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   3088\u001b[39m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/GoogleDrive-stanlee.okwii@gmail.com/My Drive/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ../datasets/imagenet2012/5.1.0/imagenet2012-train.tfrecord-00026-of-01024; Operation canceled [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset_folder = \"../datasets\"\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    dataset_folder = \"/content/drive/My Drive/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/datasets\"\n",
    "\n",
    "\n",
    "# Load the ImageNet dataset.\n",
    "print(\"Loading the ImageNet dataset...\")\n",
    "# We will only load the training split initially to get class counts.\n",
    "# The following line assumes you have a local copy of ImageNet files.\n",
    "(ds_train_full,), ds_info = tfds.load(\n",
    "    'imagenet2012',\n",
    "    split=['train'],\n",
    "    shuffle_files=False, # Important to keep order for consistent splits\n",
    "    data_dir='../datasets',\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# --- Step 1: Count samples per class ---\n",
    "# We need to get the number of samples for each class to perform a stratified split.\n",
    "# This is still a memory-intensive operation but only requires storing counts, not all images.\n",
    "print(\"Counting samples per class...\")\n",
    "\n",
    "# Create a dictionary to hold the counts for each of the 1000 ImageNet labels.\n",
    "class_counts = {label: 0 for label in range(1000)}\n",
    "for _, label in ds_train_full:\n",
    "    class_counts[label.numpy()] += 1\n",
    "\n",
    "# --- Step 2: Determine split sizes per class ---\n",
    "print(\"Calculating split sizes for 80% train and 20% validation...\")\n",
    "\n",
    "train_sizes = {}\n",
    "val_sizes = {}\n",
    "\n",
    "for label, count in class_counts.items():\n",
    "    # Calculate the number of samples for the training set (80%).\n",
    "    num_train = int(np.floor(0.8 * count))\n",
    "    train_sizes[label] = num_train\n",
    "    val_sizes[label] = count - num_train\n",
    "\n",
    "# --- Step 3: Create the final datasets using filtering and skipping ---\n",
    "# This is the memory-efficient part. We create a single shuffled dataset and then\n",
    "# filter it to build the train and validation splits.\n",
    "\n",
    "# First, create a single, unshuffled dataset from the original TFDS split.\n",
    "ds_full = tfds.load(\n",
    "    'imagenet2012',\n",
    "    split='train',\n",
    "    shuffle_files=True, # Shuffle the files for better randomness\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "# Now, we define a function to filter and get the stratified splits.\n",
    "# This approach is still not a true \"perfect\" stratification in one pass because\n",
    "# `filter` and `take` operations can be complex with large, shuffled datasets.\n",
    "# A more robust solution for perfect stratification on disk would require writing\n",
    "# to sharded files, which is more complex.\n",
    "# The following is a common and practical approximation.\n",
    "\n",
    "# Let's create a temporary list of tuples (label, item) to ensure we get the right number of samples.\n",
    "all_items = list(ds_full.as_numpy_iterator())\n",
    "np.random.shuffle(all_items) # Shuffle the combined list\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "train_counts = {label: 0 for label in range(1000)}\n",
    "val_counts = {label: 0 for label in range(1000)}\n",
    "\n",
    "for image, label in all_items:\n",
    "    if train_counts[label] < train_sizes[label]:\n",
    "        train_list.append((image, label))\n",
    "        train_counts[label] += 1\n",
    "    elif val_counts[label] < val_sizes[label]:\n",
    "        val_list.append((image, label))\n",
    "        val_counts[label] += 1\n",
    "    # Once we have enough samples for a class, we stop taking from it.\n",
    "    \n",
    "print(\"Converting lists to final datasets...\")\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: (x for x in train_list),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(224, 224, 3), dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64)\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: (x for x in val_list),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(224, 224, 3), dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64)\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Step 4: Verification ---\n",
    "print(f\"\\nTraining dataset size: {len(train_list)} samples\")\n",
    "print(f\"Validation dataset size: {len(val_list)} samples\")\n",
    "\n",
    "# Final verification of class distribution (first 10 classes)\n",
    "print(\"\\nClass distribution in Training set (first 10 classes):\")\n",
    "for label in range(10):\n",
    "    print(f\"  Class {label}: {train_counts[label]} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in Validation set (first 10 classes):\")\n",
    "for label in range(10):\n",
    "    print(f\"  Class {label}: {val_counts[label]} samples\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
