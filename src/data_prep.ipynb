{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dab9466",
      "metadata": {
        "id": "7dab9466"
      },
      "source": [
        "# Data Preprocessing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow tensorflow-datasets -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzaVqvodxSoH",
        "outputId": "91375d19-d8df-4185-b095-831415d8b724"
      },
      "id": "BzaVqvodxSoH",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8_n8JmyR-uhc",
      "metadata": {
        "id": "8_n8JmyR-uhc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # use \"3\" to hide even ERROR logs\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d4428a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4428a8",
        "outputId": "0b4a8e90-b70e-43e3-ec25-856fdd9dbfc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 200\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5 # Changed to a lower number for demonstration if retraining is needed\n",
        "tf.random.set_seed(5)\n",
        "dataset_dir = \"../datasets\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
        "    BATCH_SIZE = 450\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    tf.io.gfile.makedirs(dataset_dir)\n",
        "\n",
        "\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Available GPUs:\", physical_gpus)\n",
        "\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('float32') # Ensured float32 policy as per the original notebook\n",
        "    if physical_gpus: # Check if GPUs are available before setting virtual device\n",
        "        # tf.config.experimental.set_virtual_device_configuration(\n",
        "        #     physical_gpus[0],\n",
        "        #     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
        "        # )\n",
        "        print(\"Using GPU with 55GB of memory\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "x6x0_1gKGBqe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6x0_1gKGBqe",
        "outputId": "aa5ed75b-c94d-42bb-bed3-caab6bda4bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train image count: 1281167\n",
            "Test image count: 50000\n"
          ]
        }
      ],
      "source": [
        "# Load ImageNet data\n",
        "def prepare_input_data(input):\n",
        "    image = tf.cast(input['image'], tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Corrected to use the casted image\n",
        "    image = preprocess_input(image)\n",
        "    label = input['label']\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# dataset, info = tfds.load(\n",
        "#     'imagenette',\n",
        "#     shuffle_files=False,\n",
        "#     with_info=True,\n",
        "#     data_dir=dataset_dir\n",
        "# )\n",
        "\n",
        "\n",
        "dataset, info = tfds.load(\n",
        "    'imagenet2012',\n",
        "    shuffle_files=False,\n",
        "    with_info=True,\n",
        "    data_dir=dataset_dir\n",
        ")\n",
        "\n",
        "train_dataset_image_count = info.splits[\"train\"].num_examples\n",
        "test_dataset_image_count = info.splits[\"validation\"].num_examples\n",
        "\n",
        "print(f'Train image count: {train_dataset_image_count}')\n",
        "print(f'Test image count: {test_dataset_image_count}')\n",
        "\n",
        "train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7dbe3779",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbe3779",
        "outputId": "8355f191-065b-4307-a9d3-90664699f7ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load ResNet50 model\n",
        "# base_model = ResNet50(\n",
        "#     include_top=True,\n",
        "#     weights=None,\n",
        "#     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#     pooling=None,\n",
        "#     classes=10,\n",
        "#     classifier_activation='softmax'\n",
        "# )\n",
        "\n",
        "base_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "# Functions for adversarial data generation and loading\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
        "    x_adv = tf.identity(images)\n",
        "    # Use from_logits=False because classifier_activation='softmax' means model outputs probabilities\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "    for _ in range(nb_iter):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            prediction = model(x_adv, training=False)\n",
        "            loss = loss_object(labels, prediction)\n",
        "\n",
        "        gradients = tape.gradient(loss, x_adv)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        x_adv = x_adv + eps_iter * signed_grad\n",
        "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
        "        x_adv = images + perturbation\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def generate_adversarial_dataset_in_batches(folder, dataset, model, eps, pgd_steps, pgd_step_size, count):\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    image_count = 0\n",
        "    dataset_iterator = iter(dataset)\n",
        "    batch_count = math.ceil(count / BATCH_SIZE)\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataset_iterator):\n",
        "        batch_no = f\"{folder}-record-{i}-of-{batch_count}.tfrec\"\n",
        "        print(f\"batch_{i}\")\n",
        "        adv_images = _create_adversary_with_pgd(\n",
        "            model=model,\n",
        "            images=images,\n",
        "            labels=labels,\n",
        "            eps=eps,\n",
        "            eps_iter=pgd_step_size,\n",
        "            nb_iter=pgd_steps\n",
        "        )\n",
        "\n",
        "        with tf.io.TFRecordWriter(batch_no, options=options) as writer:\n",
        "            for i in range(len(adv_images)):\n",
        "                image_tensor = adv_images[i]\n",
        "                label = labels[i]\n",
        "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
        "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
        "                feature = {\n",
        "                    'image': _bytes_feature(image_bytes),\n",
        "                    'label': _int64_feature(label.numpy())\n",
        "                }\n",
        "                image_count += 1\n",
        "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "                writer.write(serialized_example)\n",
        "    print(f\"Processed and saved: {image_count} images\")\n",
        "\n",
        "def _parse_function(proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "    label = parsed_features['label']\n",
        "    image_f32 = tf.cast(image_f16, tf.float32)\n",
        "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return image_f32, label\n",
        "\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fBYFgK2mfy6t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBYFgK2mfy6t",
        "outputId": "8c794f96-ed63-4f18-be7e-69b1f79cf481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Training base model...\\n\")\n",
        "# base_model.fit(train_dataset, verbose=1, batch_size=BATCH_SIZE, epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lfBX8E_Nf4cu",
      "metadata": {
        "id": "lfBX8E_Nf4cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb98485a-0606-4b0e-b910-72ddf9a90766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate adversarial test data\n",
            "batch_0\n",
            "batch_1\n",
            "batch_2\n",
            "batch_3\n",
            "batch_4\n",
            "batch_5\n",
            "batch_6\n",
            "batch_7\n",
            "batch_8\n",
            "batch_9\n",
            "batch_10\n",
            "batch_11\n",
            "batch_12\n",
            "batch_13\n",
            "batch_14\n",
            "batch_15\n",
            "batch_16\n",
            "batch_17\n",
            "batch_18\n",
            "batch_19\n",
            "batch_20\n",
            "batch_21\n",
            "batch_22\n",
            "batch_23\n",
            "batch_24\n",
            "batch_25\n",
            "batch_26\n",
            "batch_27\n",
            "batch_28\n",
            "batch_29\n",
            "batch_30\n",
            "batch_31\n",
            "batch_32\n",
            "batch_33\n",
            "batch_34\n",
            "batch_35\n",
            "batch_36\n",
            "batch_37\n",
            "batch_38\n",
            "batch_39\n",
            "batch_40\n",
            "batch_41\n",
            "batch_42\n",
            "batch_43\n",
            "batch_44\n",
            "batch_45\n",
            "batch_46\n",
            "batch_47\n",
            "batch_48\n",
            "batch_49\n",
            "batch_50\n",
            "batch_51\n",
            "batch_52\n",
            "batch_53\n",
            "batch_54\n",
            "batch_55\n",
            "batch_56\n",
            "batch_57\n"
          ]
        }
      ],
      "source": [
        "# Create adversarial dataset\n",
        "EPSILON = 8/255 # Maximum allowed change.\n",
        "PGD_STEPS = 5 # use 5 steps\n",
        "PGD_STEP_SIZE = 2/255 # change by much at each step\n",
        "# adversarial_test_file = f'{dataset_dir}/adversaries/test_dataset.tfrec'\n",
        "test_dataset_folder = f'{dataset_dir}/adversaries/imagenet2012/test'\n",
        "print(\"Generate adversarial test data\")\n",
        "generate_adversarial_dataset_in_batches(\n",
        "    folder=test_dataset_folder,\n",
        "    dataset=test_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE,\n",
        "    count=test_dataset_image_count,\n",
        ")\n",
        "\n",
        "# train_dataset_folder = f'{dataset_dir}/adversaries/imagenet2012/train'\n",
        "# print(\"Generate adversarial train data\")\n",
        "# generate_adversarial_dataset_in_batches(\n",
        "#     folder=train_dataset_folder,\n",
        "#     dataset=train_dataset,\n",
        "#     model=base_model,\n",
        "#     eps=EPSILON,\n",
        "#     pgd_steps=PGD_STEPS,\n",
        "#     pgd_step_size=PGD_STEP_SIZE,\n",
        "#     count=train_dataset_image_count,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8613b641",
      "metadata": {
        "id": "8613b641"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import glob\n",
        "\n",
        "# # Use glob to get a list of all TFRecord files\n",
        "# file_paths = glob.glob(f'{dataset_dir}/adversaries/small_test/batch_*.tfrec')\n",
        "# print(f\"Found the following TFRecord files: {file_paths}\")\n",
        "\n",
        "# # Create a TFRecordDataset from the list of file paths\n",
        "# # The files are interleaved automatically for better performance\n",
        "# raw_dataset = tf.data.TFRecordDataset(file_paths,  compression_type='GZIP')\n",
        "\n",
        "# ## Load data from file\n",
        "# def _parse_function(proto):\n",
        "#     \"\"\"\n",
        "#     Parses a single example proto by deserializing the float16 tensor\n",
        "#     and casting it back to float32.\n",
        "#     \"\"\"\n",
        "#     feature_description = {\n",
        "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
        "#         'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "#     }\n",
        "#     parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "\n",
        "#     # 1. Deserialize the byte string back into a float16 tensor\n",
        "#     image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "#     label = parsed_features['label']\n",
        "\n",
        "#     # 2. Cast the image back to float32 for the model\n",
        "#     image_f32 = tf.cast(image_f16, tf.float32)\n",
        "\n",
        "#     # 3. Set the shape on the final float32 tensor\n",
        "#     image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "\n",
        "#     return image_f32, label\n",
        "\n",
        "# # Load the TFRecord file back into a dataset\n",
        "# # loaded_test_dataset = tf.data.TFRecordDataset(adversarial_test_file, compression_type='GZIP')\n",
        "\n",
        "# parsed_test_dataset = raw_dataset.map(_parse_function).batch(200).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# def count_images_in_dataset(dataset):\n",
        "#     \"\"\"\n",
        "#     Counts the number of images in an unbatched TF.data.Dataset.\n",
        "\n",
        "#     Args:\n",
        "#         dataset: The unbatched tf.data.Dataset containing the images.\n",
        "\n",
        "#     Returns:\n",
        "#         The total number of images as an integer.\n",
        "#     \"\"\"\n",
        "#     # Use cardinality() to get the number of elements.\n",
        "#     # This is the most efficient method as it doesn't require iterating.\n",
        "#     count = tf.data.experimental.cardinality(dataset).numpy()\n",
        "\n",
        "#     # If cardinality is unknown, fall back to iterating\n",
        "#     if count == tf.data.experimental.UNKNOWN_CARDINALITY:\n",
        "#         print(\"Dataset cardinality is unknown. Counting via iteration...\")\n",
        "#         count = sum(1 for _ in dataset)\n",
        "\n",
        "#     return count\n",
        "\n",
        "\n",
        "# # Use the function to count the images in the raw, unbatched dataset\n",
        "# total_images = count_images_in_dataset(raw_dataset)\n",
        "# print(f\"Total number of images in the dataset: {total_images}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}