{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dab9466",
      "metadata": {
        "id": "7dab9466"
      },
      "source": [
        "# Data Preprocessing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install tensorflow tensorflow-datasets -q"
      ],
      "metadata": {
        "id": "BzaVqvodxSoH",
        "outputId": "83c42340-9b1a-4c2b-f24f-07213300e949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BzaVqvodxSoH",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8_n8JmyR-uhc",
      "metadata": {
        "id": "8_n8JmyR-uhc",
        "outputId": "61945e5f-107b-437b-c9c6-b16e3495d980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # use \"3\" to hide even ERROR logs\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1d4428a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4428a8",
        "outputId": "9eebc240-5cf0-44d7-f61a-3fe9f8079f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 200\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5 # Changed to a lower number for demonstration if retraining is needed\n",
        "tf.random.set_seed(5)\n",
        "dataset_dir = \"../datasets\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
        "    BATCH_SIZE = 500\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    tf.io.gfile.makedirs(dataset_dir)\n",
        "\n",
        "\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Available GPUs:\", physical_gpus)\n",
        "\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('float32') # Ensured float32 policy as per the original notebook\n",
        "    if physical_gpus: # Check if GPUs are available before setting virtual device\n",
        "        # tf.config.experimental.set_virtual_device_configuration(\n",
        "        #     physical_gpus[0],\n",
        "        #     [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
        "        # )\n",
        "        print(\"Using GPU with 55GB of memory\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "x6x0_1gKGBqe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6x0_1gKGBqe",
        "outputId": "6553d7a2-1c82-40d0-9bd8-8ee328659fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train image count: 3925\n",
            "Test image count: 3925\n"
          ]
        }
      ],
      "source": [
        "# Load ImageNet data\n",
        "def prepare_input_data(input):\n",
        "    image = tf.cast(input['image'], tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Corrected to use the casted image\n",
        "    image = preprocess_input(image)\n",
        "    label = input['label']\n",
        "    return image, label\n",
        "\n",
        "\n",
        "dataset, info = tfds.load(\n",
        "    'imagenette',\n",
        "    shuffle_files=False,\n",
        "    with_info=True,\n",
        "    data_dir=dataset_dir\n",
        ")\n",
        "\n",
        "\n",
        "# dataset, info = tfds.load(\n",
        "#     'imagenet2012',\n",
        "#     shuffle_files=False,\n",
        "#     with_info=True,\n",
        "#     data_dir=dataset_dir\n",
        "# )\n",
        "\n",
        "train_dataset_image_count = info.splits[\"train\"].num_examples\n",
        "test_dataset_image_count = info.splits[\"validation\"].num_examples\n",
        "\n",
        "print(f'Train image count: {test_dataset_image_count}')\n",
        "print(f'Test image count: {test_dataset_image_count}')\n",
        "\n",
        "train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7dbe3779",
      "metadata": {
        "id": "7dbe3779"
      },
      "outputs": [],
      "source": [
        "# Load ResNet50 model\n",
        "base_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=10,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "# base_model = ResNet50(\n",
        "#     include_top=True,\n",
        "#     weights='imagenet',\n",
        "#     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#     pooling=None,\n",
        "#     classes=1000,\n",
        "#     classifier_activation='softmax'\n",
        "# )\n",
        "\n",
        "# Functions for adversarial data generation and loading\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
        "    x_adv = tf.identity(images)\n",
        "    # Use from_logits=False because classifier_activation='softmax' means model outputs probabilities\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "    for _ in range(nb_iter):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            prediction = model(x_adv, training=False)\n",
        "            loss = loss_object(labels, prediction)\n",
        "\n",
        "        gradients = tape.gradient(loss, x_adv)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        x_adv = x_adv + eps_iter * signed_grad\n",
        "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
        "        x_adv = images + perturbation\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "def generate_adversarial_dataset_in_batches(folder, dataset, model, eps, pgd_steps, pgd_step_size, count):\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    image_count = 0\n",
        "    dataset_iterator = iter(dataset)\n",
        "    batch_count = math.ceil(count / BATCH_SIZE)\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataset_iterator):\n",
        "        batch_no = f\"{folder}-record-{i}-of-{batch_count}.tfrec\"\n",
        "        print(f\"batch_{i}\")\n",
        "        adv_images = _create_adversary_with_pgd(\n",
        "            model=model,\n",
        "            images=images,\n",
        "            labels=labels,\n",
        "            eps=eps,\n",
        "            eps_iter=pgd_step_size,\n",
        "            nb_iter=pgd_steps\n",
        "        )\n",
        "\n",
        "        with tf.io.TFRecordWriter(batch_no, options=options) as writer:\n",
        "            for i in range(len(adv_images)):\n",
        "                image_tensor = adv_images[i]\n",
        "                label = labels[i]\n",
        "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
        "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
        "                feature = {\n",
        "                    'image': _bytes_feature(image_bytes),\n",
        "                    'label': _int64_feature(label.numpy())\n",
        "                }\n",
        "                image_count += 1\n",
        "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "                writer.write(serialized_example)\n",
        "    print(f\"Processed and saved: {image_count} images\")\n",
        "\n",
        "def _parse_function(proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "    label = parsed_features['label']\n",
        "    image_f32 = tf.cast(image_f16, tf.float32)\n",
        "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return image_f32, label\n",
        "\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fBYFgK2mfy6t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBYFgK2mfy6t",
        "outputId": "b93558f2-5ecb-4d35-90fa-662b05f55b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model...\n",
            "\n",
            "Epoch 1/4\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 12s/step - accuracy: 0.2034 - loss: 3.4433 - top_5_accuracy: 0.6531\n",
            "Epoch 2/4\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 12s/step - accuracy: 0.3952 - loss: 1.8030 - top_5_accuracy: 0.8559\n",
            "Epoch 3/4\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 12s/step - accuracy: 0.4966 - loss: 1.5165 - top_5_accuracy: 0.9085\n",
            "Epoch 4/4\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 12s/step - accuracy: 0.5965 - loss: 1.2714 - top_5_accuracy: 0.9406\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa13c299fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(\"Training base model...\\n\")\n",
        "base_model.fit(train_dataset, verbose=1, batch_size=BATCH_SIZE, epochs=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lfBX8E_Nf4cu",
      "metadata": {
        "id": "lfBX8E_Nf4cu",
        "outputId": "cede208c-7ad5-43ce-85b9-ad9ef6dab418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate adversarial test data\n",
            "batch_0\n",
            "batch_1\n",
            "batch_2\n",
            "batch_3\n",
            "batch_4\n",
            "batch_5\n",
            "batch_6\n",
            "batch_7\n",
            "Processed and saved: 3925 images\n",
            "Generate adversarial train data\n",
            "batch_0\n",
            "batch_1\n",
            "batch_2\n",
            "batch_3\n",
            "batch_4\n",
            "batch_5\n",
            "batch_6\n",
            "batch_7\n",
            "batch_8\n",
            "batch_9\n",
            "batch_10\n",
            "batch_11\n",
            "batch_12\n",
            "batch_13\n",
            "batch_14\n",
            "batch_15\n",
            "batch_16\n",
            "batch_17\n",
            "batch_18\n",
            "Processed and saved: 9469 images\n"
          ]
        }
      ],
      "source": [
        "# Create adversarial dataset\n",
        "EPSILON = 8/255 # Maximum allowed change.\n",
        "PGD_STEPS = 5 # use 5 steps\n",
        "PGD_STEP_SIZE = 2/255 # change by much at each step\n",
        "# adversarial_test_file = f'{dataset_dir}/adversaries/test_dataset.tfrec'\n",
        "test_dataset_folder = f'{dataset_dir}/adversaries/imagenette/test'\n",
        "print(\"Generate adversarial test data\")\n",
        "generate_adversarial_dataset_in_batches(\n",
        "    folder=test_dataset_folder,\n",
        "    dataset=test_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE,\n",
        "    count=test_dataset_image_count,\n",
        ")\n",
        "\n",
        "train_dataset_folder = f'{dataset_dir}/adversaries/imagenette/train'\n",
        "print(\"Generate adversarial train data\")\n",
        "generate_adversarial_dataset_in_batches(\n",
        "    folder=train_dataset_folder,\n",
        "    dataset=train_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE,\n",
        "    count=train_dataset_image_count,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8613b641",
      "metadata": {
        "id": "8613b641"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import glob\n",
        "\n",
        "# # Use glob to get a list of all TFRecord files\n",
        "# file_paths = glob.glob(f'{dataset_dir}/adversaries/small_test/batch_*.tfrec')\n",
        "# print(f\"Found the following TFRecord files: {file_paths}\")\n",
        "\n",
        "# # Create a TFRecordDataset from the list of file paths\n",
        "# # The files are interleaved automatically for better performance\n",
        "# raw_dataset = tf.data.TFRecordDataset(file_paths,  compression_type='GZIP')\n",
        "\n",
        "# ## Load data from file\n",
        "# def _parse_function(proto):\n",
        "#     \"\"\"\n",
        "#     Parses a single example proto by deserializing the float16 tensor\n",
        "#     and casting it back to float32.\n",
        "#     \"\"\"\n",
        "#     feature_description = {\n",
        "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
        "#         'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "#     }\n",
        "#     parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "\n",
        "#     # 1. Deserialize the byte string back into a float16 tensor\n",
        "#     image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "#     label = parsed_features['label']\n",
        "\n",
        "#     # 2. Cast the image back to float32 for the model\n",
        "#     image_f32 = tf.cast(image_f16, tf.float32)\n",
        "\n",
        "#     # 3. Set the shape on the final float32 tensor\n",
        "#     image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "\n",
        "#     return image_f32, label\n",
        "\n",
        "# # Load the TFRecord file back into a dataset\n",
        "# # loaded_test_dataset = tf.data.TFRecordDataset(adversarial_test_file, compression_type='GZIP')\n",
        "\n",
        "# parsed_test_dataset = raw_dataset.map(_parse_function).batch(200).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# def count_images_in_dataset(dataset):\n",
        "#     \"\"\"\n",
        "#     Counts the number of images in an unbatched TF.data.Dataset.\n",
        "\n",
        "#     Args:\n",
        "#         dataset: The unbatched tf.data.Dataset containing the images.\n",
        "\n",
        "#     Returns:\n",
        "#         The total number of images as an integer.\n",
        "#     \"\"\"\n",
        "#     # Use cardinality() to get the number of elements.\n",
        "#     # This is the most efficient method as it doesn't require iterating.\n",
        "#     count = tf.data.experimental.cardinality(dataset).numpy()\n",
        "\n",
        "#     # If cardinality is unknown, fall back to iterating\n",
        "#     if count == tf.data.experimental.UNKNOWN_CARDINALITY:\n",
        "#         print(\"Dataset cardinality is unknown. Counting via iteration...\")\n",
        "#         count = sum(1 for _ in dataset)\n",
        "\n",
        "#     return count\n",
        "\n",
        "\n",
        "# # Use the function to count the images in the raw, unbatched dataset\n",
        "# total_images = count_images_in_dataset(raw_dataset)\n",
        "# print(f\"Total number of images in the dataset: {total_images}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V6E1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}