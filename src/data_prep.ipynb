{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dab9466",
      "metadata": {
        "id": "7dab9466"
      },
      "source": [
        "# Data Preprocessing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-datasets -q"
      ],
      "metadata": {
        "id": "BjGYC-4uAbas",
        "outputId": "66c4f335-1a55-43a7-ae83-5c3e37cc609d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BjGYC-4uAbas",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "# 0 = all logs, 1 = filter INFO, 2 = filter INFO & WARNING, 3 = filter INFO, WARNING & ERROR\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # use \"3\" to hide even ERROR logs\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Silence TensorFlow's Python logger as well\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Silence absl logs that TF uses\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "\n",
        "try:\n",
        "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "8_n8JmyR-uhc"
      },
      "id": "8_n8JmyR-uhc",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d4428a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4428a8",
        "outputId": "f534e73a-cc60-449f-b586-d27c75a1d6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 200\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5 # Changed to a lower number for demonstration if retraining is needed\n",
        "tf.random.set_seed(5)\n",
        "dataset_dir = \"../datasets\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
        "    BATCH_SIZE = 200\n",
        "\n",
        "\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Available GPUs:\", physical_gpus)\n",
        "\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('float32') # Ensured float32 policy as per the original notebook\n",
        "    if physical_gpus: # Check if GPUs are available before setting virtual device\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            physical_gpus[0],\n",
        "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
        "        )\n",
        "        print(\"Using GPU with 55GB of memory\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ImageNet data\n",
        "def prepare_input_data(input):\n",
        "    image = tf.cast(input['image'], tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Corrected to use the casted image\n",
        "    image = preprocess_input(image)\n",
        "    label = input['label']\n",
        "    return image, label\n",
        "\n",
        "# Ensure the directory exists\n",
        "tf.io.gfile.makedirs(dataset_dir)\n",
        "\n",
        "# dataset, info = tfds.load(\n",
        "#     'imagenette',\n",
        "#     shuffle_files=False,\n",
        "#     with_info=True,\n",
        "#     data_dir=dataset_dir\n",
        "# )\n",
        "\n",
        "# builder = tfds.builder('imagenet2012', data_dir=dataset_dir)\n",
        "# builder.download_and_prepare(download_dir=dataset_dir) # Use local_data_dir for temp too\n",
        "dataset, info = tfds.load(\n",
        "    'imagenet2012',\n",
        "    shuffle_files=False,\n",
        "    with_info=True,\n",
        "    data_dir=dataset_dir\n",
        ")\n",
        "\n",
        "print(f'Train image count: {info.splits[\"train\"].num_examples}')\n",
        "print(f'Test image count: {info.splits[\"validation\"].num_examples}')\n",
        "\n",
        "train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6x0_1gKGBqe",
        "outputId": "09c7d8a2-5705-45f2-bfcc-6888c9b51366"
      },
      "id": "x6x0_1gKGBqe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /content/drive/Othercomputers/Big Mac/datasets/imagenet2012/5.1.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3379f04cccd94b00936e42e7847ba42e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0c82d93e7ed44cf95ad521dfa7b7af0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbe3779",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbe3779",
        "outputId": "8292b727-b955-43b5-c2ed-4f4120d584ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train image count: 9469\n",
            "Test image count: 3925\n"
          ]
        }
      ],
      "source": [
        "# Load ResNet50 model\n",
        "# base_model = ResNet50(\n",
        "#     include_top=True,\n",
        "#     weights=None,\n",
        "#     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#     pooling=None,\n",
        "#     classes=10,\n",
        "#     classifier_activation='softmax'\n",
        "# )\n",
        "\n",
        "base_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "# Functions for adversarial data generation and loading\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
        "    x_adv = tf.identity(images)\n",
        "    # Use from_logits=False because classifier_activation='softmax' means model outputs probabilities\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "    for _ in range(nb_iter):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            prediction = model(x_adv, training=False)\n",
        "            loss = loss_object(labels, prediction)\n",
        "\n",
        "        gradients = tape.gradient(loss, x_adv)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        x_adv = x_adv + eps_iter * signed_grad\n",
        "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
        "        x_adv = images + perturbation\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "def generate_adversarial_dataset(filename, dataset, model, eps, pgd_steps, pgd_step_size):\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    num = 0\n",
        "    dataset_iterator = iter(dataset)\n",
        "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
        "        for i, (images, labels) in enumerate(dataset_iterator):\n",
        "            print(f\"Batch {i+1}\")\n",
        "            adv_images = _create_adversary_with_pgd(\n",
        "                model=model,\n",
        "                images=images,\n",
        "                labels=labels,\n",
        "                eps=eps,\n",
        "                eps_iter=pgd_step_size,\n",
        "                nb_iter=pgd_steps\n",
        "            )\n",
        "\n",
        "            for i in range(len(adv_images)):\n",
        "                image_tensor = adv_images[i]\n",
        "                label = labels[i]\n",
        "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
        "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
        "                feature = {\n",
        "                    'image': _bytes_feature(image_bytes),\n",
        "                    'label': _int64_feature(label.numpy())\n",
        "                }\n",
        "                num += 1\n",
        "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "                writer.write(serialized_example)\n",
        "    print(f\"Processed and saved: {num} images\")\n",
        "\n",
        "def _parse_function(proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "    label = parsed_features['label']\n",
        "    image_f32 = tf.cast(image_f16, tf.float32)\n",
        "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return image_f32, label\n",
        "\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training base model...\\n\")\n",
        "base_model.fit(train_dataset, verbose=1, batch_size=2, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBYFgK2mfy6t",
        "outputId": "689d52fc-10a4-4d13-992d-c0598f115849"
      },
      "id": "fBYFgK2mfy6t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model...\n",
            "\n",
            "Epoch 1/4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create adversarial dataset (uncomment to run generation)\n",
        "EPSILON = 8/255 # Maximum allowed change.\n",
        "PGD_STEPS = 5 # use 5 steps\n",
        "PGD_STEP_SIZE = 2/255 # change by much at each step\n",
        "adversarial_test_file = f'{dataset_dir}/adversaries/test_dataset.tfrec'\n",
        "print(\"Generate adversarial test data\")\n",
        "generate_adversarial_dataset(\n",
        "    filename=adversarial_test_file,\n",
        "    dataset=test_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE\n",
        ")\n",
        "adversarial_train_file = f'{dataset_dir}/adversaries/train_dataset.tfrec'\n",
        "print(\"Generate adversarial train data\")\n",
        "generate_adversarial_dataset(\n",
        "    filename=adversarial_train_file,\n",
        "    dataset=train_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE\n",
        ")\n"
      ],
      "metadata": {
        "id": "lfBX8E_Nf4cu"
      },
      "id": "lfBX8E_Nf4cu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}