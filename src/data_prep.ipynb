{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7dab9466",
      "metadata": {
        "id": "7dab9466"
      },
      "source": [
        "# Data Preprocessing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "# 0 = all logs, 1 = filter INFO, 2 = filter INFO & WARNING, 3 = filter INFO, WARNING & ERROR\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # use \"3\" to hide even ERROR logs\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Silence TensorFlow's Python logger as well\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Silence absl logs that TF uses\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "\n",
        "try:\n",
        "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "8_n8JmyR-uhc"
      },
      "id": "8_n8JmyR-uhc",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d4428a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d4428a8",
        "outputId": "b46c39ab-5ef5-43cf-f504-91b447a86d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 200\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5 # Changed to a lower number for demonstration if retraining is needed\n",
        "tf.random.set_seed(5)\n",
        "dataset_dir = \"../datasets\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
        "\n",
        "\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Available GPUs:\", physical_gpus)\n",
        "\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('float32') # Ensured float32 policy as per the original notebook\n",
        "    if physical_gpus: # Check if GPUs are available before setting virtual device\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            physical_gpus[0],\n",
        "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
        "        )\n",
        "        print(\"Using GPU with 55GB of memory\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4040305c",
      "metadata": {
        "id": "4040305c",
        "outputId": "08aa9843-01e1-42ef-85e9-30f31ee7b416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train image count: 1281167\n",
            "Test image count: 50000\n"
          ]
        }
      ],
      "source": [
        "# Load ImageNet data\n",
        "\n",
        "def prepare_input_data(input):\n",
        "    image = tf.cast(input['image'], tf.float32)\n",
        "    image = tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE)\n",
        "    image = preprocess_input(image)\n",
        "    label = input['label']\n",
        "    return image, label\n",
        "\n",
        "# Imagenet full dataset\n",
        "# dataset, info = tfds.load(\n",
        "#     'imagenet2012',\n",
        "#     shuffle_files=False,\n",
        "#     with_info=True,\n",
        "#     data_dir='../datasets'\n",
        "# )\n",
        "\n",
        "# Imagenet smallet dataset dataset\n",
        "dataset, info = tfds.load(\n",
        "    'imagenet2012',\n",
        "    shuffle_files=False,\n",
        "    with_info=True,\n",
        "    data_dir='../datasets'\n",
        ")\n",
        "\n",
        "# Dataset stats\n",
        "print(f'Train image count: {info.splits['train'].num_examples}')\n",
        "print(f'Test image count: {info.splits['validation'].num_examples}')\n",
        "\n",
        "# Preprocess data\n",
        "# train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "# test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbe3779",
      "metadata": {
        "id": "7dbe3779"
      },
      "outputs": [],
      "source": [
        "# Load ResNet50 model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\n",
        "base_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "base_model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a298a3",
      "metadata": {
        "id": "28a298a3"
      },
      "outputs": [],
      "source": [
        "filename = '../datasets/adversaries/test_dataset1.tfrecord'\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
        "    x_adv = tf.identity(images)\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "    for _ in range(nb_iter):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            prediction = model(x_adv, training=False)\n",
        "            loss = loss_object(labels, prediction)\n",
        "\n",
        "        gradients = tape.gradient(loss, x_adv)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        x_adv = x_adv + eps_iter * signed_grad\n",
        "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
        "        x_adv = images + perturbation\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "def generate_adversarial_dataset(dataset, model, eps, pgd_steps, pgd_step_size):\n",
        "    \"\"\"\n",
        "    Generates adversarial examples and saves them to a TFRecord file\n",
        "    by serializing the raw float32 tensors.\n",
        "    \"\"\"\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    n = 0\n",
        "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
        "        for i, (images, labels) in enumerate(dataset):\n",
        "            print(f\"Batch {i+1}\")\n",
        "            # Generate the adversarial images (these are already preprocessed)\n",
        "            adv_images = _create_adversary_with_pgd(\n",
        "                model=model,\n",
        "                images=images,\n",
        "                labels=labels,\n",
        "                eps=eps,\n",
        "                eps_iter=pgd_step_size,\n",
        "                nb_iter=pgd_steps\n",
        "            )\n",
        "\n",
        "            # Iterate through the batch to save each image/label pair\n",
        "            for i in range(len(adv_images)):\n",
        "                image_tensor = adv_images[i]\n",
        "                label = labels[i]\n",
        "\n",
        "                # 1. Cast the tensor to float16 to halve its size\n",
        "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
        "\n",
        "                # 2. Serialize the smaller tensor\n",
        "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
        "                # 2. Create the feature and write to the TFRecord file\n",
        "                feature = {\n",
        "                    'image': _bytes_feature(image_bytes), # Save the raw serialized tensor\n",
        "                    'label': _int64_feature(label.numpy())\n",
        "                }\n",
        "                n += 1\n",
        "\n",
        "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "                writer.write(serialized_example)\n",
        "\n",
        "    print(\"Created adversary dataset and saved: \", n, '\\n')\n",
        "\n",
        "\n",
        "def create_adversarial_dataset_direct(dataset, model, eps, pgd_steps, pgd_step_size):\n",
        "    adversarial_images = []\n",
        "    adversarial_labels = []\n",
        "\n",
        "    # Iterate through each batch in the original dataset\n",
        "    for i, (images, labels) in enumerate(dataset):\n",
        "        print(f\" batch {i+1}...\")\n",
        "        # Generate adversarial examples for the current batch using our custom function\n",
        "        adv_images = _create_adversary_with_pgd(\n",
        "            model=model,\n",
        "            images=images,\n",
        "            labels=labels,\n",
        "            eps=eps,\n",
        "            eps_iter=pgd_step_size,\n",
        "            nb_iter=pgd_steps\n",
        "        )\n",
        "\n",
        "        # Append the results to our lists\n",
        "        adversarial_images.append(adv_images)\n",
        "        adversarial_labels.append(labels)\n",
        "\n",
        "    # Concatenate all batches into single tensors\n",
        "    adversarial_images = tf.concat(adversarial_images, axis=0)\n",
        "    adversarial_labels = tf.concat(adversarial_labels, axis=0)\n",
        "\n",
        "    # Create a new dataset from the adversarial examples\n",
        "    adversarial_dataset = tf.data.Dataset.from_tensor_slices((adversarial_images, adversarial_labels))\n",
        "\n",
        "    # Apply the same batching and prefetching for evaluation compatibility\n",
        "    adversarial_dataset = adversarial_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    return adversarial_dataset\n",
        "\n",
        "EPSILON = 0.03\n",
        "PGD_STEPS = 2\n",
        "PGD_STEP_SIZE = 0.007"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e703c6d2",
      "metadata": {
        "id": "e703c6d2",
        "outputId": "bd00d6a8-b97e-41cf-ddc0-64eaf121c675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1\n",
            "Batch 2\n",
            "Batch 3\n",
            "Created adversary dataset and saved:  600 \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-19 18:12:39.887445: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
          ]
        }
      ],
      "source": [
        "## Create adversarial dataset\n",
        "generate_adversarial_dataset(\n",
        "    dataset=test_dataset.take(3),\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE\n",
        ")\n",
        "\n",
        "# _new_test = create_adversarial_dataset_direct(\n",
        "#     dataset=test_dataset.take(3),\n",
        "#     model=base_model,\n",
        "#     eps=EPSILON,\n",
        "#     pgd_steps=PGD_STEPS,\n",
        "#     pgd_step_size=PGD_STEP_SIZE\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779eed6b",
      "metadata": {
        "id": "779eed6b"
      },
      "outputs": [],
      "source": [
        "# --- How to load the data back ---\n",
        "\n",
        "def _parse_function(proto):\n",
        "    \"\"\"\n",
        "    Parses a single example proto by deserializing the float16 tensor\n",
        "    and casting it back to float32.\n",
        "    \"\"\"\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "\n",
        "    # 1. Deserialize the byte string back into a float16 tensor\n",
        "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "    label = parsed_features['label']\n",
        "\n",
        "    # 2. Cast the image back to float32 for the model\n",
        "    image_f32 = tf.cast(image_f16, tf.float32)\n",
        "\n",
        "    # 3. Set the shape on the final float32 tensor\n",
        "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "\n",
        "    return image_f32, label\n",
        "\n",
        "# Load the TFRecord file back into a dataset\n",
        "loaded_dataset = tf.data.TFRecordDataset(filename, compression_type='GZIP')\n",
        "\n",
        "# Map the parsing function across the dataset\n",
        "parsed_dataset = loaded_dataset.map(_parse_function).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a248a933",
      "metadata": {
        "id": "a248a933",
        "outputId": "95ac6d4b-c876-4839-a845-feaa7f28f65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x34d9e8540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x34d9e8540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation Results from data loaded from file ---\n",
            "Loss: 1.6013\n",
            "Top-1 Accuracy: 64.25%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "results = base_model.evaluate(parsed_dataset, verbose=0, batch_size=10, steps=2)\n",
        "\n",
        "print(\"\\n--- Evaluation Results from data loaded from file ---\")\n",
        "print(f\"Loss: {results[0]:.4f}\")\n",
        "print(f\"Top-1 Accuracy: {results[1] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0d13f4",
      "metadata": {
        "id": "cf0d13f4"
      },
      "outputs": [],
      "source": [
        "# results = base_model.evaluate(_new_test, verbose=0, batch_size=10, steps=2)\n",
        "\n",
        "# print(\"\\n--- Evaluation Results from directly generated data ---\")\n",
        "# print(f\"Loss: {results[0]:.4f}\")\n",
        "# print(f\"Top-1 Accuracy: {results[1] * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}