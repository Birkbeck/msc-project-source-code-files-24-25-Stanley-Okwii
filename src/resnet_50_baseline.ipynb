{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c71fe7c",
      "metadata": {
        "id": "6c71fe7c"
      },
      "source": [
        "# Resnet model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "zGU_Lbbm5dHT",
      "metadata": {
        "id": "zGU_Lbbm5dHT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "# 0 = all logs, 1 = filter INFO, 2 = filter INFO & WARNING, 3 = filter INFO, WARNING & ERROR\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # use \"3\" to hide even ERROR logs\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Silence TensorFlow's Python logger as well\n",
        "tf.get_logger().setLevel(\"ERROR\")\n",
        "\n",
        "# Silence absl logs that TF uses\n",
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "\n",
        "try:\n",
        "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ihBZpnsN5kyY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihBZpnsN5kyY",
        "outputId": "e36e3736-daf7-4caf-b536-e94cdce463a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Available GPUs: []\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 200\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "EPOCHS = 5 # Changed to a lower number for demonstration if retraining is needed\n",
        "tf.random.set_seed(5)\n",
        "dataset_dir = \"../datasets\"\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
        "\n",
        "\n",
        "physical_gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Available GPUs:\", physical_gpus)\n",
        "\n",
        "try:\n",
        "    tf.keras.mixed_precision.set_global_policy('float32') # Ensured float32 policy as per the original notebook\n",
        "    if physical_gpus: # Check if GPUs are available before setting virtual device\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            physical_gpus[0],\n",
        "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
        "        )\n",
        "        print(\"Using GPU with 55GB of memory\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4daff7df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ImageNet data\n",
        "def prepare_input_data(input):\n",
        "    image = tf.cast(input['image'], tf.float32)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE)) # Corrected to use the casted image\n",
        "    image = preprocess_input(image)\n",
        "    label = input['label']\n",
        "    return image, label\n",
        "\n",
        "# dataset, info = tfds.load(\n",
        "#     'imagenette',\n",
        "#     shuffle_files=False,\n",
        "#     with_info=True,\n",
        "#     data_dir=dataset_dir\n",
        "# )\n",
        "dataset, info = tfds.load(\n",
        "    'imagenet2012',\n",
        "    shuffle_files=False,\n",
        "    with_info=True,\n",
        "    data_dir=dataset_dir\n",
        ")\n",
        "\n",
        "print(f'Train image count: {info.splits[\"train\"].num_examples}')\n",
        "print(f'Test image count: {info.splits[\"validation\"].num_examples}')\n",
        "\n",
        "train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "# Load ResNet50 model\n",
        "# base_model = ResNet50(\n",
        "#     include_top=True,\n",
        "#     weights=None,\n",
        "#     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#     pooling=None,\n",
        "#     classes=10,\n",
        "#     classifier_activation='softmax'\n",
        "# )\n",
        "\n",
        "base_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "# Functions for adversarial data generation and loading\n",
        "def _bytes_feature(value):\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
        "    x_adv = tf.identity(images)\n",
        "    # Use from_logits=False because classifier_activation='softmax' means model outputs probabilities\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "    for _ in range(nb_iter):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(x_adv)\n",
        "            prediction = model(x_adv, training=False)\n",
        "            loss = loss_object(labels, prediction)\n",
        "\n",
        "        gradients = tape.gradient(loss, x_adv)\n",
        "        signed_grad = tf.sign(gradients)\n",
        "        x_adv = x_adv + eps_iter * signed_grad\n",
        "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
        "        x_adv = images + perturbation\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "def generate_adversarial_dataset(filename, dataset, model, eps, pgd_steps, pgd_step_size):\n",
        "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "    num = 0\n",
        "    dataset_iterator = iter(dataset)\n",
        "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
        "        for i, (images, labels) in enumerate(dataset_iterator):\n",
        "            print(f\"Batch {i+1}\")\n",
        "            adv_images = _create_adversary_with_pgd(\n",
        "                model=model,\n",
        "                images=images,\n",
        "                labels=labels,\n",
        "                eps=eps,\n",
        "                eps_iter=pgd_step_size,\n",
        "                nb_iter=pgd_steps\n",
        "            )\n",
        "\n",
        "            for i in range(len(adv_images)):\n",
        "                image_tensor = adv_images[i]\n",
        "                label = labels[i]\n",
        "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
        "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
        "                feature = {\n",
        "                    'image': _bytes_feature(image_bytes),\n",
        "                    'label': _int64_feature(label.numpy())\n",
        "                }\n",
        "                num += 1\n",
        "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
        "                writer.write(serialized_example)\n",
        "    print(f\"Processed and saved: {num} images\")\n",
        "\n",
        "def _parse_function(proto):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
        "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
        "    label = parsed_features['label']\n",
        "    image_f32 = tf.cast(image_f16, tf.float32)\n",
        "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
        "    return image_f32, label\n",
        "\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee61ee2",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training base model...\\n\")\n",
        "# base_model.fit(train_dataset, verbose=1, batch_size=BATCH_SIZE, epochs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d14f3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create adversarial dataset (uncomment to run generation)\n",
        "EPSILON = 8/255 # Maximum allowed change.\n",
        "PGD_STEPS = 5 # use 5 steps\n",
        "PGD_STEP_SIZE = 2/255 # change by much at each step\n",
        "adversarial_test_file = f'{dataset_dir}/adversaries/test_dataset.tfrec'\n",
        "print(\"Generate adversarial test data\")\n",
        "generate_adversarial_dataset(\n",
        "    filename=adversarial_test_file,\n",
        "    dataset=test_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE\n",
        ")\n",
        "adversarial_train_file = f'{dataset_dir}/adversaries/train_dataset.tfrec'\n",
        "print(\"Generate adversarial train data\")\n",
        "generate_adversarial_dataset(\n",
        "    filename=adversarial_train_file,\n",
        "    dataset=train_dataset,\n",
        "    model=base_model,\n",
        "    eps=EPSILON,\n",
        "    pgd_steps=PGD_STEPS,\n",
        "    pgd_step_size=PGD_STEP_SIZE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba61e511",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "loaded_test_dataset = tf.data.TFRecordDataset(adversarial_test_file, compression_type='GZIP')\n",
        "parsed_test_dataset = loaded_test_dataset.map(_parse_function).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Computing baseline metrics...\\n\")\n",
        "\n",
        "train_metrics = base_model.evaluate(train_dataset, verbose=1)\n",
        "test_metrics = base_model.evaluate(test_dataset, verbose=1)\n",
        "noisy_metrics = base_model.evaluate(parsed_test_dataset, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "382aaba1",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Extract metrics\n",
        "try:\n",
        "    metric_names = ['loss', 'accuracy', 'top_5_accuracy']\n",
        "    metrics_dict = {\n",
        "        'train': dict(zip(metric_names, train_metrics)),\n",
        "        'test': dict(zip(metric_names, test_metrics)),\n",
        "        'noisy': dict(zip(metric_names, noisy_metrics))\n",
        "    }\n",
        "\n",
        "    train_loss, train_acc, train_top5 = metrics_dict['train'].values()\n",
        "    test_loss, test_acc, test_top5 = metrics_dict['test'].values()\n",
        "    noisy_loss, noisy_acc, noisy_top5 = metrics_dict['noisy'].values()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting metrics: {e}\")\n",
        "\n",
        "print(\"## Baseline Performance Metrics ðŸ“Š\")\n",
        "print(f\"Clean Data Accuracy: `{test_acc*100:.2f}%`\")\n",
        "print(f\"Adversarial Data Accuracy: `{noisy_acc*100:.2f}%`\")\n",
        "print(f\"* Robustness Gap: `{(test_acc-noisy_acc)*100:.2f}%`\")\n",
        "\n",
        "print(\"\\n\" + \"---\")\n",
        "print(f\"Top-1 Accuracy: `{test_acc*100:.2f}%`\")\n",
        "print(f\"Top-5 Accuracy: `{test_top5*100:.2f}%`\")\n",
        "print(f\"Loss: `{test_loss:.3f}`\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ba023e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adversarial training\n",
        "loaded_train_dataset = tf.data.TFRecordDataset(adversarial_train_file, compression_type='GZIP')\n",
        "parsed_train_dataset = loaded_train_dataset.map(_parse_function).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Adversarial Training robust model...\\n\")\n",
        "\n",
        "# robust_model = ResNet50(\n",
        "#     include_top=True,\n",
        "#     weights=None,\n",
        "#     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "#     pooling=None,\n",
        "#     classes=10,\n",
        "#     classifier_activation='softmax'\n",
        "# )\n",
        "#\n",
        "robust_model = ResNet50(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'\n",
        ")\n",
        "\n",
        "robust_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "    ]\n",
        ")\n",
        "robust_model.fit(parsed_train_dataset, verbose=1, batch_size=BATCH_SIZE, epochs=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48607c6",
      "metadata": {
        "id": "a48607c6",
        "outputId": "dc4acf24-6d72-45c0-ef9c-d175079bdd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Using GPU with 55GB of memory\n",
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ../datasets/imagenet2012/5.1.0...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                         \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset imagenet2012 downloaded and prepared to ../datasets/imagenet2012/5.1.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "Train image count: 1281167\n",
            "Test image count: 50000\n",
            "Training baseline model...\n",
            "\n",
            "Epoch 1/4\n",
            "\u001b[1m6406/6406\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12606s\u001b[0m 2s/step - accuracy: 0.5888 - loss: 1.6944 - top_5_accuracy: 0.8293\n",
            "Epoch 2/4\n",
            "\u001b[1m6406/6406\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12525s\u001b[0m 2s/step - accuracy: 0.6959 - loss: 1.1874 - top_5_accuracy: 0.8979\n",
            "Epoch 3/4\n",
            "\u001b[1m6406/6406\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12640s\u001b[0m 2s/step - accuracy: 0.7627 - loss: 0.8899 - top_5_accuracy: 0.9337\n",
            "Epoch 4/4\n",
            "\u001b[1m 570/6406\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m3:10:27\u001b[0m 2s/step - accuracy: 0.7918 - loss: 0.7675 - top_5_accuracy: 0.9478"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 182\u001b[39m\n\u001b[32m    172\u001b[39m base_model.compile(\n\u001b[32m    173\u001b[39m     optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    174\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m     ]\n\u001b[32m    179\u001b[39m )\n\u001b[32m    181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining baseline model...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Create adversarial dataset (uncomment to run generation)\u001b[39;00m\n\u001b[32m    185\u001b[39m EPSILON = \u001b[32m8\u001b[39m/\u001b[32m255\u001b[39m \u001b[38;5;66;03m# Maximum allowed change.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Adversarial evaluation\n",
        "train_metrics_adv = robust_model.evaluate(parsed_train_dataset, verbose=1)\n",
        "test_metrics_adv = robust_model.evaluate(test_dataset, verbose=1)\n",
        "noisy_metrics_adv = robust_model.evaluate(parsed_test_dataset, verbose=1)\n",
        "\n",
        "try:\n",
        "    metrics_dict_adv = {\n",
        "        'train': dict(zip(metric_names, train_metrics_adv)),\n",
        "        'test': dict(zip(metric_names, test_metrics_adv)),\n",
        "        'noisy': dict(zip(metric_names, noisy_metrics_adv))\n",
        "    }\n",
        "\n",
        "    train_loss_adv, train_acc_adv, train_top5_adv = metrics_dict_adv['train'].values()\n",
        "    test_loss_adv, test_acc_adv, test_top5_adv = metrics_dict_adv['test'].values()\n",
        "    noisy_loss_adv, noisy_acc_adv, noisy_top5_adv = metrics_dict_adv['noisy'].values()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error extracting metrics after adversarial training: {e}\")\n",
        "    print(\"Available metrics:\", base_model.metrics_names)\n",
        "    raise\n",
        "\n",
        "# Create figure for multiple plots - After adversarial training\n",
        "plt.style.use('seaborn-v0_8-darkgrid') # Updated style for better visuals\n",
        "fig = plt.figure(figsize=(18, 6)) # Larger figure size\n",
        "\n",
        "# 1. Accuracy Comparison (Post-Adversarial Training)\n",
        "plt.subplot(1, 3, 1)\n",
        "metrics = ['Top-1 Acc', 'Top-5 Acc']\n",
        "clean_scores_post_adv = [test_acc_adv*100, test_top5_adv*100]\n",
        "noisy_scores_post_adv = [noisy_acc_adv*100, noisy_top5_adv*100]\n",
        "\n",
        "x = range(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar([i - width/2 for i in x], clean_scores_post_adv, width, label='Clean Data', color='mediumseagreen')\n",
        "plt.bar([i + width/2 for i in x], noisy_scores_post_adv, width, label='Adversarial Data', color='salmon')\n",
        "plt.ylabel('Percentage (%)')\n",
        "plt.title('Accuracy Comparison (Post-Adversarial Training)')\n",
        "plt.xticks(x, metrics)\n",
        "plt.legend()\n",
        "plt.ylim(0, 100) # Set y-limit for better comparison\n",
        "\n",
        "# 2. Loss Comparison (Post-Adversarial Training)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.bar(['Training', 'Testing', 'Adversarial'],\n",
        "        [train_loss_adv, test_loss_adv, noisy_loss_adv],\n",
        "        color=['steelblue', 'mediumseagreen', 'salmon'])\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Comparison Across Datasets (Post-Adversarial Training)')\n",
        "\n",
        "# 3. Robustness Gap (Post-Adversarial Training)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(['Generalization Gap', 'Robustness Gap'],\n",
        "        [(train_acc_adv - test_acc_adv)*100, (test_acc_adv - noisy_acc_adv)*100],\n",
        "        color=['steelblue', 'salmon'])\n",
        "plt.ylabel('Gap Percentage (%)')\n",
        "plt.title('Model Gaps Analysis (Post-Adversarial Training)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed metrics report (Post-Adversarial Training)\n",
        "print(\"## Adversarial Performance Metrics ðŸ“Š\")\n",
        "print(f\"Clean Data Accuracy: `{test_acc_adv*100:.2f}%`\")\n",
        "print(f\"Adversarial Data Accuracy: `{noisy_acc_adv*100:.2f}%`\")\n",
        "print(f\"Robustness Gap: `{(test_acc_adv-noisy_acc_adv)*100:.2f}%`\")\n",
        "\n",
        "print(f\"Top-1 Accuracy: `{test_acc_adv*100:.2f}%`\")\n",
        "print(f\"Top-5 Accuracy: `{test_top5_adv*100:.2f}%`\")\n",
        "print(f\"Loss: `{test_loss_adv:.3f}`\")\n",
        "\n",
        "print(\"\\n## Generalization Analysis ðŸ§ \")\n",
        "print(f\"Training Accuracy: `{train_acc_adv*100:.2f}%`\")\n",
        "print(f\"Test Accuracy: `{test_acc_adv*100:.2f}%`\")\n",
        "print(f\"Generalization Gap: `{(train_acc_adv-test_acc_adv)*100:.2f}%`\")\n",
        "print(f\"Training Loss: `{train_loss_adv:.3f}`\")\n",
        "print(f\"Test Loss: `{test_loss_adv:.3f}`\")\n",
        "print(\"> *A smaller gap indicates better generalization*\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f8730f",
      "metadata": {
        "id": "e0f8730f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
