{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71380ef4",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee633cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3cdbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using available GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 300\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "EPOCHS = 5\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "tf.random.set_seed(5)\n",
    "dataset_dir = \"../datasets\"\n",
    "\n",
    "# Change dataset_dir when run in google colab \n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
    "    BATCH_SIZE = 430\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    tf.io.gfile.makedirs(dataset_dir)\n",
    "\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Using available GPUs: \", physical_gpus)\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1140fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 128116\n",
      "Validation[:50%] count: 25000\n",
      "Validation[50%:] (test) count: 25000\n",
      "No of classes 1000\n"
     ]
    }
   ],
   "source": [
    "# Load ImageNet2012 subset dataset\n",
    "def prepare_input_data(input):\n",
    "    image = tf.cast(input['image'], tf.float32)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = preprocess_input(image)\n",
    "    label = input['label']\n",
    "    return image, label\n",
    "\n",
    "def make_dataset(ds):\n",
    "    return (\n",
    "        ds.map(prepare_input_data, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "(train, validation, test), info = tfds.load(\n",
    "    'imagenet2012_subset/10pct',\n",
    "    split=['train', 'validation[:50%]', 'validation[50%:]'],\n",
    "    shuffle_files=False,\n",
    "    with_info=True,\n",
    "    data_dir=dataset_dir\n",
    ")\n",
    "\n",
    "num_classes = info.features['label'].num_classes\n",
    "\n",
    "print(f\"Train count: {info.splits['train'].num_examples}\")\n",
    "print(f\"Validation count: {info.splits['validation[:50%]'].num_examples}\")\n",
    "print(f\"Test count: {info.splits['validation[50%:]'].num_examples}\")\n",
    "print(f\"No of classes {num_classes}\")\n",
    "\n",
    "train_dataset = make_dataset(train)\n",
    "validation_dataset = make_dataset(validation)\n",
    "test_dataset = make_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462faf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate dataset class distribution\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def class_counts_from_raw_ds(raw_ds, num_classes):\n",
    "    # Map to one-hot labels and sum across the dataset\n",
    "    counts = (\n",
    "    raw_ds\n",
    "    .map(lambda x: tf.one_hot(x['label'], num_classes, dtype=tf.int64),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "    .batch(4096)\n",
    "    .reduce(\n",
    "        initial_state=tf.zeros([num_classes], dtype=tf.int64),\n",
    "        reduce_func=lambda acc, x: acc + tf.reduce_sum(x, axis=0)\n",
    "    )\n",
    "    )\n",
    "    return counts.numpy()\n",
    "\n",
    "def print_distribution(name, counts, class_names=None, top_k=5):\n",
    "    total = counts.sum()\n",
    "    print(f\"\\n{name}: total={total}, classes={len(counts)}\")\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(len(counts))]\n",
    "    # Show a quick summary: most/least frequent classes\n",
    "    idx_sorted = np.argsort(counts)\n",
    "    print(f\"Least frequent {top_k}:\")\n",
    "    for i in idx_sorted[:top_k]:\n",
    "        print(f\"{i:4d} {class_names[i]:30s} {int(counts[i]):7d} ({counts[i]/total:.2%})\")\n",
    "        print(f\"Most frequent {top_k}:\")\n",
    "    for i in idx_sorted[-top_k:][::-1]:\n",
    "        print(f\"{i:4d} {class_names[i]:30s} {int(counts[i]):7d} ({counts[i]/total:.2%})\")\n",
    "\n",
    "\n",
    "train_counts = class_counts_from_raw_ds(train, num_classes)\n",
    "val_counts = class_counts_from_raw_ds(validation, num_classes)\n",
    "test_counts = class_counts_from_raw_ds(test, num_classes)\n",
    "\n",
    "print_distribution(\"Train dataset\", train_counts, class_names)\n",
    "print_distribution(\"Validation dataset\", val_counts, class_names)\n",
    "print_distribution(\"Test dataset\", test_counts, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4328611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb70e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # get value from EagerTensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
    "    \"\"\"\n",
    "    This generates adversarial images by iteratively applying a small\n",
    "    perturbation in the direction of the gradient of the loss, and then\n",
    "    projecting the result back into the epsilon-ball of the original image.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The model to attack.\n",
    "        images (tf.Tensor): The original, clean input images.\n",
    "        labels (tf.Tensor): The true labels for the images.\n",
    "        eps (float): The maximum perturbation (L-infinity norm).\n",
    "        eps_iter (float): The step size for each attack iteration.\n",
    "        nb_iter (int): The number of PGD iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The generated adversarial images.\n",
    "    \"\"\"\n",
    "    x_adv = tf.identity(images)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    for _ in range(nb_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)\n",
    "            prediction = model(x_adv, training=False)\n",
    "            loss = loss_object(labels, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        signed_grad = tf.sign(gradients)\n",
    "        x_adv = x_adv + eps_iter * signed_grad\n",
    "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
    "        x_adv = images + perturbation\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "def generate_adversarial_dataset(folder, dataset, model, eps, steps, step_size):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples and saves them to a TFRecord file\n",
    "    by serializing the raw float32 tensors.\n",
    "    \"\"\"\n",
    "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "    total_images_processed = 0\n",
    "    dataset_inter = iter(dataset)\n",
    "\n",
    "    cardinality = tf.data.experimental.cardinality(dataset)\n",
    "    if cardinality == tf.data.experimental.UNKNOWN_CARDINALITY:\n",
    "        print(\"Warning: Dataset cardinality is unknown. Filenames will use 'N' for total batches.\")\n",
    "        total_no_of_batches = \"N\"\n",
    "    else:\n",
    "        total_no_of_batches = cardinality.numpy()\n",
    "        print(f\"Dataset has a total of {total_no_of_batches} batches.\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataset_inter):\n",
    "        print(f\"Processing record {i+1} out of {total_no_of_batches}\")\n",
    "        filename = f\"{folder}-record-{i+1}-of-{total_no_of_batches}.tfrec\"\n",
    "        # Generate the adversarial images (these are already preprocessed)\n",
    "        adv_images = _create_adversary_with_pgd(\n",
    "            model=model,\n",
    "            images=images,\n",
    "            labels=labels,\n",
    "            eps=eps,\n",
    "            eps_iter=step_size,\n",
    "            nb_iter=steps\n",
    "        )\n",
    "        with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
    "            # Iterate through the batch to save each image/label pair\n",
    "            for i in range(len(adv_images)):\n",
    "                image_tensor = adv_images[i]\n",
    "                label = labels[i]\n",
    "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
    "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
    "                feature = {\n",
    "                    'image': _bytes_feature(image_bytes), # Save the raw serialized tensor\n",
    "                    'label': _int64_feature(label.numpy())\n",
    "                }\n",
    "                total_images_processed += 1\n",
    "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
    "                writer.write(serialized_example)\n",
    "\n",
    "    print(f\"Processed and saved {total_images_processed} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d8765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial validation data\n",
      "Dataset has a total of 84 batches.\n",
      "Processing record 1 out of 84\n",
      "Processing record 2 out of 84\n",
      "Processing record 3 out of 84\n",
      "Processing record 4 out of 84\n",
      "Processing record 5 out of 84\n",
      "Processing record 6 out of 84\n",
      "Processing record 7 out of 84\n",
      "Processing record 8 out of 84\n",
      "Processing record 9 out of 84\n",
      "Processing record 10 out of 84\n",
      "Processing record 11 out of 84\n",
      "Processing record 12 out of 84\n",
      "Processing record 13 out of 84\n",
      "Processing record 14 out of 84\n",
      "Processing record 15 out of 84\n",
      "Processing record 16 out of 84\n",
      "Processing record 17 out of 84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/var/folders/dp/vgygxyts0hx4hnzrgrnmgpm80000gn/T/ipykernel_8616/2227607719.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m validation_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/validation\"\n\u001b[32m     18\u001b[39m print(\u001b[33m\"Generating adversarial validation data\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m generate_adversarial_dataset(\n\u001b[32m     20\u001b[39m     folder=validation_folder,\n\u001b[32m     21\u001b[39m     dataset=validation_dataset,\n\u001b[32m     22\u001b[39m     model=base_model,\n",
      "\u001b[32m/var/folders/dp/vgygxyts0hx4hnzrgrnmgpm80000gn/T/ipykernel_8616/1143307046.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(folder, dataset, model, eps, steps, step_size)\u001b[39m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;28;01min\u001b[39;00m enumerate(dataset_inter):\n\u001b[32m     62\u001b[39m         print(f\"Processing record {i+\u001b[32m1\u001b[39m} out of {total_no_of_batches}\")\n\u001b[32m     63\u001b[39m         filename = f\"{folder}-record-{i+\u001b[32m1\u001b[39m}-of-{total_no_of_batches}.tfrec\"\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# Generate the adversarial images (these are already preprocessed)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m         adv_images = _create_adversary_with_pgd(\n\u001b[32m     66\u001b[39m             model=model,\n\u001b[32m     67\u001b[39m             images=images,\n\u001b[32m     68\u001b[39m             labels=labels,\n",
      "\u001b[32m/var/folders/dp/vgygxyts0hx4hnzrgrnmgpm80000gn/T/ipykernel_8616/1143307046.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model, images, labels, eps, eps_iter, nb_iter)\u001b[39m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;28;01min\u001b[39;00m range(nb_iter):\n\u001b[32m     31\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     32\u001b[39m             tape.watch(x_adv)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m             prediction = model(x_adv, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     34\u001b[39m             loss = loss_object(labels, prediction)\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m         gradients = tape.gradient(loss, x_adv)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs,\n\u001b[32m    185\u001b[39m             operation_fn=lambda op: operation_fn(\n\u001b[32m    186\u001b[39m                 op, training=training, **kwargs\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/ops/function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    202\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m                     \u001b[38;5;66;03m# Use NNX operation mapping\u001b[39;00m\n\u001b[32m    204\u001b[39m                     operation = self._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m                     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    207\u001b[39m \n\u001b[32m    208\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    640\u001b[39m                 \u001b[38;5;28;01mand\u001b[39;00m value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m             ):\n\u001b[32m    642\u001b[39m                 kwargs[name] = value\n\u001b[32m    643\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/layers/normalization/batch_normalization.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask)\u001b[39m\n\u001b[32m    273\u001b[39m             beta = ops.cast(self.beta, inputs.dtype)\n\u001b[32m    274\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    275\u001b[39m             beta = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    276\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         outputs = ops.batch_normalization(\n\u001b[32m    278\u001b[39m             x=inputs,\n\u001b[32m    279\u001b[39m             mean=mean,\n\u001b[32m    280\u001b[39m             variance=variance,\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/ops/nn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, mean, variance, axis, offset, scale, epsilon)\u001b[39m\n\u001b[32m   2263\u001b[39m         return BatchNorm(axis, epsilon).symbolic_call(\n\u001b[32m   2264\u001b[39m             x, mean, variance, offset, scale\n\u001b[32m   2265\u001b[39m         )\n\u001b[32m   2266\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m2267\u001b[39m     return backend.nn.batch_normalization(\n\u001b[32m   2268\u001b[39m         x, mean, variance, axis, offset, scale, epsilon\n\u001b[32m   2269\u001b[39m     )\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, mean, variance, axis, offset, scale, epsilon)\u001b[39m\n\u001b[32m    875\u001b[39m             offset = tf.reshape(offset, shape)\n\u001b[32m    876\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    877\u001b[39m             scale = tf.reshape(scale, shape)\n\u001b[32m    878\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     return tf.nn.batch_normalization(\n\u001b[32m    880\u001b[39m         x=x,\n\u001b[32m    881\u001b[39m         mean=mean,\n\u001b[32m    882\u001b[39m         variance=variance,\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/nn_impl.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001b[39m\n\u001b[32m   1483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scale \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1484\u001b[39m       inv *= scale\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001b[39;00m\n\u001b[32m   1486\u001b[39m     \u001b[38;5;66;03m# the precise order of ops that are generated by the expression below.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m     return x * math_ops.cast(inv, x.dtype) + math_ops.cast(\n\u001b[32m   1488\u001b[39m         offset - mean * inv \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m -mean * inv, x.dtype)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/framework/override_binary_operator.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[32m    111\u001b[39m         \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[32m    112\u001b[39m         x, y = maybe_promote_tensors(x, y)\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(x, y, name=name)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    115\u001b[39m         \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[32m    116\u001b[39m         \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[32m    117\u001b[39m         \u001b[38;5;66;03m# and the tensor.\u001b[39;00m\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/tensor_math_operator_overrides.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m _mul_dispatch_factory(x, y, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     62\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m tensorflow.python.ops \u001b[38;5;28;01mimport\u001b[39;00m math_ops\n\u001b[32m     63\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m math_ops._mul_dispatch(x, y, name=name)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   1701\u001b[39m     new_vals = gen_sparse_ops.sparse_dense_cwise_mul(y.indices, y.values,\n\u001b[32m   1702\u001b[39m                                                      y.dense_shape, x, name)\n\u001b[32m   1703\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sparse_tensor.SparseTensor(y.indices, new_vals, y.dense_shape)\n\u001b[32m   1704\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m multiply(x, y, name=name)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m    145\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m    520\u001b[39m \n\u001b[32m    521\u001b[39m    * InvalidArgumentError: When `x` \u001b[38;5;28;01mand\u001b[39;00m `y` have incompatible shapes \u001b[38;5;28;01mor\u001b[39;00m types.\n\u001b[32m    522\u001b[39m   \"\"\"\n\u001b[32m    523\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops.mul(x, y, name)\n",
      "\u001b[32m~/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   6825\u001b[39m         _ctx, \u001b[33m\"Mul\"\u001b[39m, name, x, y)\n\u001b[32m   6826\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6827\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   6828\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m6829\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   6830\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   6831\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   6832\u001b[39m       return mul_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Generate adversarial train data\n",
    "EPSILON = 8/255\n",
    "STEPS = 2\n",
    "STEP_SIZE = 8/255\n",
    "\n",
    "train_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/train\"\n",
    "print(\"Generating adversarial train data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=train_folder,\n",
    "    dataset=train_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n",
    "\n",
    "\n",
    "validation_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/validation\"\n",
    "print(\"Generating adversarial validation data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=validation_folder,\n",
    "    dataset=validation_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n",
    "\n",
    "\n",
    "test_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/test\"\n",
    "print(\"Generating adversarial test data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=test_folder,\n",
    "    dataset=test_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
