{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71380ef4",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee633cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3cdbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using available GPUs:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 300\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "EPOCHS = 5\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "tf.random.set_seed(5)\n",
    "dataset_dir = \"../datasets\"\n",
    "\n",
    "# Change dataset_dir when run in google colab \n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount('/content/drive')\n",
    "    dataset_dir = \"/content/drive/Othercomputers/Big Mac/datasets\"\n",
    "    BATCH_SIZE = 430\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    tf.io.gfile.makedirs(dataset_dir)\n",
    "\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Using available GPUs: \", physical_gpus)\n",
    "\n",
    "tf.keras.mixed_precision.set_global_policy('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1140fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 128116\n",
      "Validation count: 25000\n",
      "Test count: 25000\n",
      "No of classes 1000\n"
     ]
    }
   ],
   "source": [
    "# Load ImageNet2012 subset dataset\n",
    "def prepare_input_data(input):\n",
    "    image = tf.cast(input['image'], tf.float32)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = preprocess_input(image)\n",
    "    label = input['label']\n",
    "    return image, label\n",
    "\n",
    "def make_dataset(ds):\n",
    "    return (\n",
    "        ds.map(prepare_input_data, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "(train, validation, test), info = tfds.load(\n",
    "    'imagenet2012_subset/10pct',\n",
    "    split=['train', 'validation[:50%]', 'validation[50%:]'],\n",
    "    shuffle_files=False,\n",
    "    with_info=True,\n",
    "    data_dir=dataset_dir\n",
    ")\n",
    "\n",
    "num_classes = info.features['label'].num_classes\n",
    "\n",
    "print(f\"Train count: {info.splits['train'].num_examples}\")\n",
    "print(f\"Validation count: {info.splits['validation[:50%]'].num_examples}\")\n",
    "print(f\"Test count: {info.splits['validation[50%:]'].num_examples}\")\n",
    "print(f\"No of classes {num_classes}\")\n",
    "\n",
    "train_dataset = make_dataset(train)\n",
    "validation_dataset = make_dataset(validation)\n",
    "test_dataset = make_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462faf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate dataset class distribution\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def class_counts_from_raw_ds(raw_ds, num_classes):\n",
    "    # Map to one-hot labels and sum across the dataset\n",
    "    counts = (\n",
    "        raw_ds\n",
    "            .map(lambda x: tf.one_hot(x['label'], num_classes, dtype=tf.int64),\n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "            .batch(4096)\n",
    "            .reduce(\n",
    "                initial_state=tf.zeros([num_classes], dtype=tf.int64),\n",
    "                reduce_func=lambda acc, x: acc + tf.reduce_sum(x, axis=0)\n",
    "            )\n",
    "    )\n",
    "    return counts.numpy()\n",
    "\n",
    "def print_distribution(name, counts, class_names=None, top_k=5):\n",
    "    total = counts.sum()\n",
    "    print(f\"\\n{name}: total={total}, classes={len(counts)}\")\n",
    "    if class_names is None:\n",
    "        class_names = [str(i) for i in range(len(counts))]\n",
    "\n",
    "    # Show a quick summary: most/least frequent classes\n",
    "    idx_sorted = np.argsort(counts)\n",
    "    print(f\"Least frequent {top_k}:\")\n",
    "    for i in idx_sorted[:top_k]:\n",
    "        print(f\"{i:4d} {class_names[i]:30s} {int(counts[i]):7d} ({counts[i]/total:.2%})\")\n",
    "        print(f\"Most frequent {top_k}:\")\n",
    "    for i in idx_sorted[-top_k:][::-1]:\n",
    "        print(f\"{i:4d} {class_names[i]:30s} {int(counts[i]):7d} ({counts[i]/total:.2%})\")\n",
    "\n",
    "\n",
    "train_counts = class_counts_from_raw_ds(train, num_classes)\n",
    "val_counts = class_counts_from_raw_ds(validation, num_classes)\n",
    "test_counts = class_counts_from_raw_ds(test, num_classes)\n",
    "\n",
    "print_distribution(\"Train dataset\", train_counts, class_names)\n",
    "print_distribution(\"Validation dataset\", val_counts, class_names)\n",
    "print_distribution(\"Test dataset\", test_counts, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4328611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb70e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # get value from EagerTensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
    "    \"\"\"\n",
    "    This generates adversarial images by iteratively applying a small\n",
    "    perturbation in the direction of the gradient of the loss, and then\n",
    "    projecting the result back into the epsilon-ball of the original image.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The model to attack.\n",
    "        images (tf.Tensor): The original, clean input images.\n",
    "        labels (tf.Tensor): The true labels for the images.\n",
    "        eps (float): The maximum perturbation (L-infinity norm).\n",
    "        eps_iter (float): The step size for each attack iteration.\n",
    "        nb_iter (int): The number of PGD iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The generated adversarial images.\n",
    "    \"\"\"\n",
    "    x_adv = tf.identity(images)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    for _ in range(nb_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)\n",
    "            prediction = model(x_adv, training=False)\n",
    "            loss = loss_object(labels, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        signed_grad = tf.sign(gradients)\n",
    "        x_adv = x_adv + eps_iter * signed_grad\n",
    "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
    "        x_adv = images + perturbation\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "def generate_adversarial_dataset(folder, dataset, model, eps, steps, step_size):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples and saves them to a TFRecord file\n",
    "    by serializing the raw float32 tensors.\n",
    "    \"\"\"\n",
    "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "    total_images_processed = 0\n",
    "    dataset_inter = iter(dataset)\n",
    "\n",
    "    cardinality = tf.data.experimental.cardinality(dataset)\n",
    "    if cardinality == tf.data.experimental.UNKNOWN_CARDINALITY:\n",
    "        print(\"Warning: Dataset cardinality is unknown. Filenames will use 'N' for total batches.\")\n",
    "        total_no_of_batches = \"N\"\n",
    "    else:\n",
    "        total_no_of_batches = cardinality.numpy()\n",
    "        print(f\"Dataset has a total of {total_no_of_batches} batches.\")\n",
    "\n",
    "    for i, (images, labels) in enumerate(dataset_inter):\n",
    "        print(f\"Processing record {i+1} out of {total_no_of_batches}\")\n",
    "        filename = f\"{folder}-record-{i+1}-of-{total_no_of_batches}.tfrec\"\n",
    "        # Generate the adversarial images (these are already preprocessed)\n",
    "        adv_images = _create_adversary_with_pgd(\n",
    "            model=model,\n",
    "            images=images,\n",
    "            labels=labels,\n",
    "            eps=eps,\n",
    "            eps_iter=step_size,\n",
    "            nb_iter=steps\n",
    "        )\n",
    "        with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
    "            # Iterate through the batch to save each image/label pair\n",
    "            for i in range(len(adv_images)):\n",
    "                image_tensor = adv_images[i]\n",
    "                label = labels[i]\n",
    "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
    "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
    "                feature = {\n",
    "                    'image': _bytes_feature(image_bytes), # Save the raw serialized tensor\n",
    "                    'label': _int64_feature(label.numpy())\n",
    "                }\n",
    "                total_images_processed += 1\n",
    "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
    "                writer.write(serialized_example)\n",
    "\n",
    "    print(f\"Processed and saved {total_images_processed} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial train data\n",
    "EPSILON = 8/255\n",
    "STEPS = 2\n",
    "STEP_SIZE = 8/255\n",
    "\n",
    "train_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/train\"\n",
    "print(\"Generating adversarial train data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=train_folder,\n",
    "    dataset=train_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n",
    "\n",
    "\n",
    "validation_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/validation\"\n",
    "print(\"Generating adversarial validation data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=validation_folder,\n",
    "    dataset=validation_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n",
    "\n",
    "\n",
    "test_folder=f\"{dataset_dir}/adversaries/imagenet2012_subset/test\"\n",
    "print(\"Generating adversarial test data\")\n",
    "generate_adversarial_dataset(\n",
    "    folder=test_folder,\n",
    "    dataset=test_dataset,\n",
    "    model=base_model,\n",
    "    eps=EPSILON,\n",
    "    steps=STEPS,\n",
    "    step_size=STEP_SIZE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
