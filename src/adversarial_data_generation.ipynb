{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dab9466",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "While from imagenet might need little processing. To retrain Resnet-50 with adversarial inputs, they need to be generated. Training dataset has about 1M images, preprocessing, generates adversarial input for both training and testing datasets.\n",
    "Corresponding adversarial tensorflow records are created for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4428a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Using GPU with 55GB of memory\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "# BATCH_SIZE = 5000\n",
    "BATCH_SIZE = 200\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "EPOCHS = 5\n",
    "tf.random.set_seed(5)\n",
    "\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", physical_gpus)\n",
    "\n",
    "try:\n",
    "    tf.keras.mixed_precision.set_global_policy('float32')\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        physical_gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=56320)]  # Limit RAM to 55GB to avoid starving PC\n",
    "    )\n",
    "    print(\"Using GPU with 55GB of memory\")\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4040305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image count: 9469\n",
      "Test image count: 3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 23:45:16.984447: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-08-05 23:45:16.984475: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2025-08-05 23:45:16.984482: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2025-08-05 23:45:16.984501: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-08-05 23:45:16.984525: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load ImageNet data\n",
    "\n",
    "def prepare_input_data(input):\n",
    "    image = tf.cast(input['image'], tf.float32) # ResNet-50 used this\n",
    "    image = tf.image.resize(input['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    image = preprocess_input(image)\n",
    "    label = input['label']\n",
    "    return image, label\n",
    "\n",
    "# Big dataset for real work\n",
    "# dataset, info = tfds.load(\n",
    "#     'imagenet2012',\n",
    "#     shuffle_files=False,\n",
    "#     with_info=True,\n",
    "#     data_dir='../datasets'\n",
    "# )\n",
    "\n",
    "# Smaller dataset for testing\n",
    "dataset, info = tfds.load(\n",
    "    'imagenette',\n",
    "    shuffle_files=False,\n",
    "    with_info=True,\n",
    "    data_dir='../datasets'\n",
    ")\n",
    "\n",
    "# Dataset stats\n",
    "print(f'Train image count: {info.splits['train'].num_examples}')\n",
    "print(f'Test image count: {info.splits['validation'].num_examples}')\n",
    "\n",
    "# Preprocess data\n",
    "train_dataset = dataset['train'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_dataset = dataset['validation'].map(prepare_input_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbe3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a0c8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_processed_dataset('../datasets/adversaries/test_dataset.tfrecord', adversarial_test_dataset)\n",
    "# %reset_selective -f adversarial_test_dataset test_dataset\n",
    "# import gc;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a298a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # get value from EagerTensor\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _create_adversary_with_pgd(model, images, labels, eps, eps_iter, nb_iter):\n",
    "    \"\"\"\n",
    "    This generates adversarial images by iteratively applying a small\n",
    "    perturbation in the direction of the gradient of the loss, and then\n",
    "    projecting the result back into the epsilon-ball of the original image.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The model to attack.\n",
    "        images (tf.Tensor): The original, clean input images.\n",
    "        labels (tf.Tensor): The true labels for the images.\n",
    "        eps (float): The maximum perturbation (L-infinity norm).\n",
    "        eps_iter (float): The step size for each attack iteration.\n",
    "        nb_iter (int): The number of PGD iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: The generated adversarial images.\n",
    "    \"\"\"\n",
    "    x_adv = tf.identity(images)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    for _ in range(nb_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)\n",
    "            prediction = model(x_adv, training=False)\n",
    "            loss = loss_object(labels, prediction)\n",
    "\n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        signed_grad = tf.sign(gradients)\n",
    "        x_adv = x_adv + eps_iter * signed_grad\n",
    "        perturbation = tf.clip_by_value(x_adv - images, -eps, eps)\n",
    "        x_adv = images + perturbation\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "def generate_adversarial_dataset(filename,dataset, model, eps, pgd_steps, pgd_step_size):\n",
    "    \"\"\"\n",
    "    Generates adversarial examples and saves them to a TFRecord file\n",
    "    by serializing the raw float32 tensors.\n",
    "    \"\"\"\n",
    "    options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "    num = 0\n",
    "    with tf.io.TFRecordWriter(filename, options=options) as writer:\n",
    "        for i, (images, labels) in enumerate(dataset):\n",
    "            print(f\"Batch {i+1}\")\n",
    "            # Generate the adversarial images (these are already preprocessed)\n",
    "            adv_images = _create_adversary_with_pgd(\n",
    "                model=model,\n",
    "                images=images,\n",
    "                labels=labels,\n",
    "                eps=eps,\n",
    "                eps_iter=pgd_step_size,\n",
    "                nb_iter=pgd_steps\n",
    "            )\n",
    "\n",
    "            # Iterate through the batch to save each image/label pair\n",
    "            for i in range(len(adv_images)):\n",
    "                image_tensor = adv_images[i]\n",
    "                label = labels[i]\n",
    "\n",
    "                # 1. Cast the tensor to float16 to halve its size\n",
    "                image_tensor_f16 = tf.cast(image_tensor, tf.float16)\n",
    "\n",
    "                # 2. Serialize the smaller tensor\n",
    "                image_bytes = tf.io.serialize_tensor(image_tensor_f16)\n",
    "                # 2. Create the feature and write to the TFRecord file\n",
    "                feature = {\n",
    "                    'image': _bytes_feature(image_bytes), # Save the raw serialized tensor\n",
    "                    'label': _int64_feature(label.numpy())\n",
    "                }\n",
    "                num += 1\n",
    "                serialized_example = tf.train.Example(features=tf.train.Features(feature=feature)).SerializeToString()\n",
    "                writer.write(serialized_example)\n",
    "\n",
    "    print(f\"Processed and saved: {num} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e703c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create adversarial dataset\n",
    "EPSILON = 0.03\n",
    "PGD_STEPS = 2\n",
    "PGD_STEP_SIZE = 0.007\n",
    "adversarial_test_file = '../datasets/adversaries/small_test_dataset.tfrec'\n",
    "# generate_adversarial_dataset(\n",
    "#     filename=adversarial_test_file,\n",
    "#     dataset=test_dataset,\n",
    "#     model=base_model,\n",
    "#     eps=EPSILON,\n",
    "#     pgd_steps=PGD_STEPS,\n",
    "#     pgd_step_size=PGD_STEP_SIZE\n",
    "# )\n",
    "adversarial_train_file = '../datasets/adversaries/small_train_dataset.tfrec'\n",
    "# generate_adversarial_dataset(\n",
    "#     filename=adversarial_train_file,\n",
    "#     dataset=train_dataset,\n",
    "#     model=base_model,\n",
    "#     eps=EPSILON,\n",
    "#     pgd_steps=PGD_STEPS,\n",
    "#     pgd_step_size=PGD_STEP_SIZE\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c1b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data from file\n",
    "def _parse_function(proto):\n",
    "    \"\"\"\n",
    "    Parses a single example proto by deserializing the float16 tensor\n",
    "    and casting it back to float32.\n",
    "    \"\"\"\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
    "\n",
    "    # 1. Deserialize the byte string back into a float16 tensor\n",
    "    image_f16 = tf.io.parse_tensor(parsed_features['image'], out_type=tf.float16)\n",
    "    label = parsed_features['label']\n",
    "\n",
    "    # 2. Cast the image back to float32 for the model\n",
    "    image_f32 = tf.cast(image_f16, tf.float32)\n",
    "\n",
    "    # 3. Set the shape on the final float32 tensor\n",
    "    image_f32.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "\n",
    "    return image_f32, label\n",
    "\n",
    "# Load the TFRecord file back into a dataset\n",
    "loaded_test_dataset = tf.data.TFRecordDataset(adversarial_test_file, compression_type='GZIP')\n",
    "\n",
    "# Map the parsing function across the dataset\n",
    "parsed_test_dataset = loaded_test_dataset.map(_parse_function).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1ee463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "base_model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db083dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 23:45:19.295026: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "       Comprehensive Model Evaluation Results\n",
      "==================================================\n",
      "\n",
      "## Accuracy & Error Rate\n",
      "**Calculated on the clean, unseen test dataset.**\n",
      "\n",
      "* **Test Accuracy**: The percentage of correct predictions.\n",
      "    * `9.04%`\n",
      "* **Test Error Rate**: The percentage of incorrect predictions (`1 - Accuracy`).\n",
      "    * `90.96%`\n",
      "\n",
      "---\n",
      "\n",
      "## Generalisation 🧠\n",
      "**Measures the model's ability to perform on unseen data by comparing training and test performance.**\n",
      "\n",
      "* **Training Accuracy**: Performance on data the model was trained on.\n",
      "    * `9.39%`\n",
      "* **Test Accuracy**: Performance on new, unseen data.\n",
      "    * `9.04%`\n",
      "* **Generalisation Gap**: The difference between training and test accuracy.\n",
      "    * `0.34%`\n",
      "> *A small gap is ideal. A large gap suggests the model has **overfit** to the training data.*\n",
      "\n",
      "---\n",
      "\n",
      "## Robustness 🛡️\n",
      "**Measures how well performance holds up when the input data is perturbed.**\n",
      "\n",
      "* **Accuracy (Clean Data)**: Baseline performance on the original test set.\n",
      "    * `9.04%`\n",
      "* **Accuracy (Noisy Data)**: Performance on the perturbed test set.\n",
      "    * `8.99%`\n",
      "* **Performance Drop**: The reduction in accuracy due to the noisy data.\n",
      "    * `0.05%`\n",
      "> *A smaller drop indicates a more robust model.*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 23:52:14.284432: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2025-08-05 23:52:14.284530: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8286550425692185148\n",
      "2025-08-05 23:52:14.284545: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/BitwiseAnd/_12]]\n",
      "2025-08-05 23:52:14.284586: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10412056754719796095\n",
      "2025-08-05 23:52:14.284600: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11045578175169975825\n",
      "2025-08-05 23:52:14.284626: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6592760637294838528\n",
      "2025-08-05 23:52:14.284638: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2178945116829418640\n",
      "/Users/stanleyokwii/Documents/Birkbeck/Msc Project/msc-project-source-code-files-24-25-Stanley-Okwii/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline accuracy\")\n",
    "# results = base_model.evaluate(test_dataset, verbose=0, batch_size=10, steps=2)\n",
    "\n",
    "train_loss, train_accuracy = base_model.evaluate(train_dataset, verbose=0)\n",
    "test_loss, test_accuracy = base_model.evaluate(test_dataset, verbose=0)\n",
    "noisy_loss, noisy_accuracy = base_model.evaluate(parsed_test_dataset, verbose=0)\n",
    "\n",
    "# The following code prints the formatted report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"       Comprehensive Model Evaluation Results\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"## Accuracy & Error Rate\")\n",
    "print(\"**Calculated on the clean, unseen test dataset.**\\n\")\n",
    "print(f\"* **Test Accuracy**: The percentage of correct predictions.\\n    * `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Test Error Rate**: The percentage of incorrect predictions (`1 - Accuracy`).\\n    * `{(1 - test_accuracy) * 100:.2f}%`\")\n",
    "print(\"\\n\" + \"---\")\n",
    "\n",
    "print(\"\\n## Generalisation 🧠\")\n",
    "print(\"**Measures the model's ability to perform on unseen data by comparing training and test performance.**\\n\")\n",
    "print(f\"* **Training Accuracy**: Performance on data the model was trained on.\\n    * `{train_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Test Accuracy**: Performance on new, unseen data.\\n    * `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Generalisation Gap**: The difference between training and test accuracy.\\n    * `{(train_accuracy - test_accuracy) * 100:.2f}%`\")\n",
    "print(\"> *A small gap is ideal. A large gap suggests the model has **overfit** to the training data.*\")\n",
    "print(\"\\n\" + \"---\")\n",
    "\n",
    "print(\"\\n## Robustness 🛡️\")\n",
    "print(\"**Measures how well performance holds up when the input data is perturbed.**\\n\")\n",
    "print(f\"* **Accuracy (Clean Data)**: Baseline performance on the original test set.\\n    * `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Accuracy (Noisy Data)**: Performance on the perturbed test set.\\n    * `{noisy_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Performance Drop**: The reduction in accuracy due to the noisy data.\\n    * `{(test_accuracy - noisy_accuracy) * 100:.2f}%`\")\n",
    "print(\"> *A smaller drop indicates a more robust model.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779eed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_processed_dataset('../datasets/adversaries/train_dataset.tfrecord', adversarial_train_dataset)\n",
    "# %reset_selective -f adversarial_train_dataset train_dataset\n",
    "# import gc;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d863ee-653d-4908-a016-3b4fe06b5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adversarial training\n",
    "# Load the TFRecord file back into a dataset\n",
    "loaded_train_dataset = tf.data.TFRecordDataset(adversarial_train_file, compression_type='GZIP')\n",
    "\n",
    "# Map the parsing function across the dataset\n",
    "parsed_train_dataset = loaded_train_dataset.map(_parse_function).batch(BATCH_SIZE).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "history = base_model.fit(\n",
    "    parsed_train_dataset,\n",
    "    epochs=10, # Use a suitable number of epochs for your task\n",
    "    validation_data=parsed_test_dataset,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e221e0-59ce-4aea-a188-364b179eccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Robustness model accuracy\")\n",
    "# base_model.compile(optimizer='adam',\n",
    "#                 loss='sparse_categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])\n",
    "# results = base_model.evaluate(test_dataset, verbose=0, batch_size=10, steps=2)\n",
    "\n",
    "train_loss, train_accuracy = base_model.evaluate(train_dataset, verbose=0)\n",
    "test_loss, test_accuracy = base_model.evaluate(test_dataset, verbose=0)\n",
    "noisy_loss, noisy_accuracy = base_model.evaluate(parsed_test_dataset, verbose=0)\n",
    "\n",
    "# The following code prints the formatted report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"       Comprehensive Model Evaluation Results\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"## Accuracy & Error Rate\")\n",
    "print(f\"* **Test Accuracy**:   `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Test Error Rate**: (`1 - Accuracy`).\\n    * `{(1 - test_accuracy) * 100:.2f}%`\")\n",
    "print(\"\\n\" + \"---\")\n",
    "\n",
    "print(\"\\n## Generalisation 🧠\")\n",
    "print(\"**Measures the model's ability to perform on unseen data by comparing training and test performance.**\\n\")\n",
    "print(f\"* **Training Accuracy**: Performance on data the model was trained on.\\n    * `{train_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Test Accuracy**: Performance on new, unseen data.\\n    * `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Generalisation Gap**: The difference between training and test accuracy.\\n    * `{(train_accuracy - test_accuracy) * 100:.2f}%`\")\n",
    "print(\"> *A small gap is ideal. A large gap suggests the model has **overfit** to the training data.*\")\n",
    "print(\"\\n\" + \"---\")\n",
    "\n",
    "print(\"\\n## Robustness 🛡️\")\n",
    "print(\"**Measures how well performance holds up when the input data is perturbed.**\\n\")\n",
    "print(f\"* **Accuracy (Clean Data)**: Baseline performance on the original test set.\\n    * `{test_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Accuracy (Noisy Data)**: Performance on the perturbed test set.\\n    * `{noisy_accuracy * 100:.2f}%`\")\n",
    "print(f\"* **Performance Drop**: The reduction in accuracy due to the noisy data.\\n    * `{(test_accuracy - noisy_accuracy) * 100:.2f}%`\")\n",
    "print(\"> *A smaller drop indicates a more robust model.*\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
